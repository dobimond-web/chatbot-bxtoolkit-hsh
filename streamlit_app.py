# streamlit_app.py
import json
import re
from urllib.parse import urljoin, urlparse
from datetime import datetime

import streamlit as st
from bs4 import BeautifulSoup
import trafilatura
import requests
from openai import OpenAI

st.set_page_config(page_title="BX All-in-One Toolkit", page_icon="ğŸ§°", layout="wide")

# =========================
# í—¬í¼: í¬ë¡¤ë§/í…ìŠ¤íŠ¸ ì¶”ì¶œ
# =========================
def fetch_html(url, timeout=12):
    try:
        headers = {"User-Agent": "Mozilla/5.0 (BrandToolkit/1.0)"}
        resp = requests.get(url, headers=headers, timeout=timeout)
        if resp.status_code == 200 and "text/html" in resp.headers.get("Content-Type", ""):
            return resp.text
    except Exception:
        return None
    return None

def extract_text(html, base_url=None):
    # 1) trafilatura ì‹œë„ (ê°€ì¥ í’ˆì§ˆ ì¢‹ìŒ)
    txt = trafilatura.extract(html, include_comments=False, include_formatting=False, url=base_url)
    if txt and len(txt.split()) > 60:
        return txt.strip()
    # 2) fallback: BeautifulSoupë¡œ ê°€ë³ê²Œ ë³¸ë¬¸ë§Œ ì¶”ì¶œ
    try:
        soup = BeautifulSoup(html, "lxml")
        # script/style ì œê±°
        for tag in soup(["script", "style", "noscript"]):
            tag.decompose()
        text = " ".join(soup.get_text(separator=" ").split())
        return text
    except Exception:
        return ""

def discover_links(base_url, html, max_links=8, same_host=True):
    """í™ˆì—ì„œ 1ëìŠ¤ í•˜ì´í¼ë§í¬ë¥¼ ë½‘ì•„ ì£¼ìš” í˜ì´ì§€ ëª‡ ê°œë§Œ íƒìƒ‰"""
    try:
        soup = BeautifulSoup(html, "lxml")
        anchors = soup.find_all("a", href=True)
        links = []
        host = urlparse(base_url).netloc
        for a in anchors:
            href = a["href"].strip()
            if href.startswith("#") or href.startswith("mailto:") or href.startswith("tel:"):
                continue
            full = urljoin(base_url, href)
            if same_host and urlparse(full).netloc != host:
                continue
            if full not in links:
                links.append(full)
            if len(links) >= max_links:
                break
        return links
    except Exception:
        return []

def safe_get(url):
    html = fetch_html(url)
    if not html:
        return {"url": url, "title": url, "text": ""}
    # ì œëª© ì¶”ì¶œ
    try:
        title = BeautifulSoup(html, "lxml").title
        title = title.get_text().strip() if title else url
    except Exception:
        title = url
    text = extract_text(html, base_url=url) or ""
    return {"url": url, "title": title, "text": text}

def summarize_corpus(client, model, corpus_items, company, max_chars=7000):
    """
    ìˆ˜ì§‘ í…ìŠ¤íŠ¸ ì¼ë¶€ë§Œ(ê¸¸ì´ ì œí•œ) ë¶™ì—¬ ìš”ì•½/í•µì‹¬/ì´ìŠˆ ì •ë¦¬.
    """
    # ê¸¸ì´ ì œí•œ ì•ˆì—ì„œ ìƒ˜í”Œë§
    joined = []
    total = 0
    for item in corpus_items:
        if not item["text"]:
            continue
        snippet = item["text"][:2000]  # ê° ë¬¸ì„œì—ì„œ ì¼ë¶€ë§Œ
        block = f"\n\n[Source: {item['title']}]({item['url']})\n{snippet}"
        if total + len(block) > max_chars:
            break
        joined.append(block)
        total += len(block)
    bundle = "".join(joined) if joined else "No content collected."

    sys = (
        "You are a brand strategist. Read the provided sources and produce a Korean summary "
        "with: 1) íšŒì‚¬/ì œí’ˆ ìš”ì•½ 2) í•µì‹¬ ê°•ì Â·ì•½ì  3) ë©”ì‹œì§€/ë¹„ì£¼ì–¼ ê´€ì ì˜ ê¸°íšŒ 4) ë¦¬ë¸Œëœë”© ì‹œ ìœ„í—˜ìš”ì¸."
        "Return clean Markdown. Never invent sources."
    )
    user = f"""
íšŒì‚¬ëª…: {company}

ì•„ë˜ëŠ” ê³µì‹ ì‚¬ì´íŠ¸/ê¸°ì‚¬ ë“±ì—ì„œ ì¶”ì¶œí•œ ì¼ë¶€ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤.
ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ **ìš”ì•½/í•µì‹¬ í¬ì¸íŠ¸/ë¦¬ë¸Œëœë”© ì‹œ ê³ ë ¤ì‚¬í•­**ì„ ì‘ì„±í•˜ì„¸ìš”.
ê°€ëŠ¥í•˜ë©´ ì¸ìš© í‘œì‹œëŠ” [Source:ì œëª©](URL)ì²˜ëŸ¼ í…ìŠ¤íŠ¸ ë§í¬ í˜•íƒœë¡œ ë‚¨ê¸°ì„¸ìš”.

ìë£Œ:
{bundle}
"""
    resp = client.chat.completions.create(
        model=model,
        messages=[{"role": "system", "content": sys}, {"role": "user", "content": user}],
        temperature=0.4,
        max_tokens=900,
    )
    return resp.choices[0].message.content

# =========================
# OpenAI í´ë¼ì´ì–¸íŠ¸
# =========================
with st.sidebar:
    st.subheader("âš™ï¸ ì„¤ì •", divider="rainbow")
    default_key = st.secrets.get("OPENAI_API_KEY", "")
    openai_api_key = st.text_input("OpenAI API Key", type="password", value=default_key or "")
    model = st.selectbox("ëª¨ë¸", ["gpt-4o-mini", "gpt-4o", "gpt-4.1-mini", "gpt-4.1"], index=0)
    temperature = st.slider("ì°½ì˜ì„±(temperature)", 0.0, 2.0, 0.8, 0.1)
    max_tokens = st.slider("ìµœëŒ€ í† í°", 256, 4096, 1600, 64)

client = OpenAI(api_key=openai_api_key) if openai_api_key else None

# =========================
# ì…ë ¥ í¼
# =========================
st.title("ğŸ§° BX All-in-One Toolkit")
st.caption("ë¦¬ë¸Œëœë”© ì‹œ: ê³µì‹ í™ˆí˜ì´ì§€Â·ê¸°ì‚¬ ìë£Œë¥¼ ë¨¼ì € ë¶„ì„í•˜ê³  BXë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")

st.markdown("### ğŸ§¾ ê¸°ë³¸ ì •ë³´ ì…ë ¥")
with st.form("brief_form"):
    col1, col2 = st.columns([1,1])
    with col1:
        company = st.text_input("ê¸°ì—…ëª…*", placeholder="ì˜ˆ: ì–´ì¸ì»´í¼ë‹ˆ")
        industry = st.text_input("ì‚°ì—…/ì¹´í…Œê³ ë¦¬", placeholder="ì˜ˆ: í•€í…Œí¬, ì‹ìŒë£Œ, SaaS")
        region = st.text_input("ì‹œì¥/ì§€ì—­", placeholder="ì˜ˆ: í•œêµ­, ë¶ë¯¸, ê¸€ë¡œë²Œ")
        competitors = st.text_area("ê²½ìŸì‚¬/ë ˆí¼ëŸ°ìŠ¤", placeholder="ê²½ìŸì‚¬ ë˜ëŠ” ë²¤ì¹˜ë§ˆí¬ ë¸Œëœë“œ ë¦¬ìŠ¤íŠ¸")
    with col2:
        target = st.text_area("íƒ€ê¹ƒ/ì„¸ê·¸ë¨¼íŠ¸", placeholder="1ì°¨Â·2ì°¨ íƒ€ê¹ƒ, í˜ë¥´ì†Œë‚˜ íŠ¹ì§•")
        request = st.text_area("ìš”ì²­ì‚¬í•­(ë¸Œë¦¬í”„)*", placeholder="ë°°ê²½/ì´ìŠˆ/ëª©í‘œ/KPI ë“±")
        constraints = st.text_area("ì œì•½/ê°€ë“œë ˆì¼", placeholder="ë²•ê·œ, ì˜ˆì‚°/ì¼ì • ì œí•œ, ê¸ˆì§€ ìš”ì†Œ ë“±")

    col3, col4, col5 = st.columns([1,1,1])
    with col3:
        mode = st.selectbox("í”„ë¡œì íŠ¸ ìœ í˜•", ["ì‹ ê·œ ë¸Œëœë”©", "ë¦¬ë¸Œëœë”©", "ì„œë¹„ìŠ¤ í™•ì¥/í•˜ìœ„ë¸Œëœë“œ"], index=1)
    with col4:
        tone = st.selectbox("ë¸Œëœë“œ í†¤&ë§¤ë„ˆ", ["ë”°ëœ»/ì¹œê·¼", "ê¸°ìˆ /ì „ë¬¸", "ëŒ€ë‹´/í˜ì‹ ", "ë¯¸ë‹ˆë©€/ì •ì œ"])
    with col5:
        depth = st.selectbox("ë””í…Œì¼ ìˆ˜ì¤€", ["ìš”ì•½í˜•", "í‘œì¤€í˜•", "ìƒì„¸í˜•"], index=1)

    submitted = st.form_submit_button("ğŸš€ BX ìë£Œ ìƒì„±")

# =========================
# ë¦¬ë¸Œëœë”© ëª¨ë“œ: ìë£Œ ìˆ˜ì§‘ ì„¹ì…˜
# =========================
corpus = []
corpus_summ = ""

if mode == "ë¦¬ë¸Œëœë”©":
    st.markdown("### ğŸŒ ë¦¬ë¸Œëœë”©: ê³µì‹ ì‚¬ì´íŠ¸/ê¸°ì‚¬ ë¶„ì„")
    c1, c2 = st.columns([1,1])
    with c1:
        official = st.text_input("ê³µì‹ í™ˆí˜ì´ì§€ URL", placeholder="https://example.com")
        discover_toggle = st.toggle("í™ˆì—ì„œ ì£¼ìš” ë‚´ë¶€ ë§í¬ ìë™ ìˆ˜ì§‘(ìµœëŒ€ 8ê°œ)", value=True)
    with c2:
        article_urls = st.text_area("ê´€ë ¨ ê¸°ì‚¬Â·ë³´ë„ìë£Œ URLë“¤(ì¤„ë°”ê¿ˆìœ¼ë¡œ ì—¬ëŸ¬ ê°œ)", placeholder="https://news1...\nhttps://press2...")

    crawl = st.button("ğŸ•· ìë£Œ ìˆ˜ì§‘ ë° ìš”ì•½")
    if crawl:
        if not official and not article_urls.strip():
            st.warning("ê³µì‹ ì‚¬ì´íŠ¸ ë˜ëŠ” ê¸°ì‚¬ URL ì¤‘ ìµœì†Œ 1ê°œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        else:
            with st.spinner("ìˆ˜ì§‘ ì¤‘..."):
                # 1) ê³µì‹ ì‚¬ì´íŠ¸
                if official:
                    html = fetch_html(official)
                    if html:
                        corpus.append(safe_get(official))
                        if discover_toggle:
                            # ë‚´ë¶€ ë§í¬ ëª‡ ê°œ ë” ê°€ì ¸ì™€ì„œ ë³¸ë¬¸ ì¶”ì¶œ
                            for link in discover_links(official, html, max_links=6, same_host=True):
                                corpus.append(safe_get(link))
                # 2) ê¸°ì‚¬ë“¤
                for raw in article_urls.splitlines():
                    url = raw.strip()
                    if not url:
                        continue
                    corpus.append(safe_get(url))

            # ë¹„ì–´ìˆëŠ” í…ìŠ¤íŠ¸ ì œê±° & ì¤‘ë³µ ì œê±°
            clean = []
            seen = set()
            for item in corpus:
                key = item["url"]
                if key in seen:
                    continue
                seen.add(key)
                if item["text"] and len(item["text"].split()) > 40:
                    clean.append(item)
            corpus = clean

            st.success(f"ìˆ˜ì§‘ ì™„ë£Œ! ë¬¸ì„œ {len(corpus)}ê°œ.")
            if not corpus:
                st.info("ìœ ì˜ë¯¸í•œ ë³¸ë¬¸ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. URLì„ êµì²´í•˜ê±°ë‚˜ ë‚´ë¶€ ë§í¬ ìë™ ìˆ˜ì§‘ì„ êº¼ë³´ì„¸ìš”.")

            # ë¯¸ë¦¬ë³´ê¸° & ìš”ì•½
            if corpus and client:
                with st.spinner("ìš”ì•½ ì •ë¦¬ ì¤‘..."):
                    corpus_summ = summarize_corpus(client, model, corpus, company)
                st.subheader("ğŸ“Œ ìë£Œ ìš”ì•½(ìë™)")
                st.markdown(corpus_summ)

            # ì†ŒìŠ¤ ëª©ë¡
            if corpus:
                st.subheader("ğŸ”— ìˆ˜ì§‘ ì†ŒìŠ¤")
                for it in corpus:
                    st.markdown(f"- [{it['title']}]({it['url']})")

# =========================
# BX ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸/ìœ ì € í”„ë¡¬í”„íŠ¸
# =========================
def build_system_prompt():
    return (
        "You are a senior brand strategist and BX architect. "
        "Produce rigorous, production-ready brand strategy & experience documentation in Korean. "
        "Use clear sectioning, bullets, and tables where helpful. Always provide practical examples."
    )

def build_user_prompt(company, industry, region, competitors, target, mode, request, constraints, tone, depth, corpus_summ, sources):
    richness = {"ìš”ì•½í˜•": "succinct with key bullets",
                "í‘œì¤€í˜•": "balanced detail with examples",
                "ìƒì„¸í˜•": "deep detail with frameworks, matrices and examples"}[depth]
    src_block = ""
    if corpus_summ:
        src_block = f"\n\n[ë¦¬ë¸Œëœë”© ì°¸ê³  ìë£Œ ìš”ì•½]\n{corpus_summ}\n\n"
        if sources:
            src_block += "[ì°¸ê³  ì†ŒìŠ¤ ëª©ë¡]\n" + "\n".join([f"- {s['title']} ({s['url']})" for s in sources[:12]]) + "\n\n"

    return f"""
ë‹¤ìŒ ê¸°ì—…ì— ëŒ€í•´ BX ì „ ê³¼ì • ë¬¸ì„œë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”. ê²°ê³¼ëŠ” **í•œêµ­ì–´**ë¡œ, Markdownìœ¼ë¡œ êµ¬ì¡°í™”í•©ë‹ˆë‹¤.
íŠ¹íˆ ë¦¬ë¸Œëœë”©ì¼ ê²½ìš° ì œê³µëœ ìë£Œ ìš”ì•½/ì†ŒìŠ¤ì— ê¸°ë°˜í•´ ì‘ì„±í•˜ê³ , ë§í¬ë¥¼ ìƒˆë¡œ ë§Œë“¤ê±°ë‚˜ ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”.

[ê¸°ì—…/ì‹œì¥ ì •ë³´]
- ê¸°ì—…ëª…: {company}
- ì‚°ì—…/ì¹´í…Œê³ ë¦¬: {industry or 'N/A'}
- ì‹œì¥/ì§€ì—­: {region or 'N/A'}
- ê²½ìŸ/ë ˆí¼ëŸ°ìŠ¤: {competitors or 'N/A'}
- íƒ€ê¹ƒ/ì„¸ê·¸ë¨¼íŠ¸: {target or 'N/A'}
- í”„ë¡œì íŠ¸ ìœ í˜•: {mode}
- ìš”ì²­ì‚¬í•­/ë¸Œë¦¬í”„: {request}
- ì œì•½/ê°€ë“œë ˆì¼: {constraints or 'N/A'}
- í†¤&ë§¤ë„ˆ: {tone}
- ìƒì„¸ ìˆ˜ì¤€: {depth} â†’ {richness}

{src_block}
[í•„ìˆ˜ ì„¹ì…˜]
1) íšŒì‚¬/ì‹œì¥/ê²½ìŸ ë¶„ì„
2) ë¸Œëœë“œ ì „ëµ(ë¯¸ì…˜/ë¹„ì „/ê°€ì¹˜Â·í¬ì§€ì…”ë‹Â·ê°€ì¹˜ì œì•ˆ)
3) ë©”ì‹œì§• ì‹œìŠ¤í…œ(ë©”ì‹œì§€ í”¼ë¼ë¯¸ë“œ/ìŠ¬ë¡œê±´/í”¼ì¹˜)
4) ì•„ì´ë´í‹°í‹° ë°©í–¥(ë¬´ë“œ/ë¡œê³  ì»¨ì…‰/ì»¬ëŸ¬Â·íƒ€ì´í¬/ëª¨ì…˜/ì ‘ê·¼ì„±)
5) ì–´í”Œë¦¬ì¼€ì´ì…˜ ì ìš© ê³„íš(ë””ì§€í„¸/ì˜¤í”„ë¼ì¸/ì»¤ë®¤ë‹ˆì¼€ì´ì…˜; ìš°ì„ ìˆœìœ„/ë‚œì´ë„/íš¨ê³¼)
6) ë¸Œëœë“œ ê²½í—˜ ì—¬ì • & í„°ì¹˜í¬ì¸íŠ¸ ë§¤íŠ¸ë¦­ìŠ¤
7) ë¡ ì¹˜/ìš´ì˜ í”Œëœ & KPI(30/60/90)
8) ì‚°ì¶œë¬¼ ì²´í¬ë¦¬ìŠ¤íŠ¸
9) ì°¸ê³  ì‚¬ë¡€/ê°€ì´ë“œ ì œì•ˆ(í…ìŠ¤íŠ¸ ë§í¬ ëª©ë¡)

ì‹¤í–‰ ê°€ëŠ¥í•˜ê³  êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•˜ê³ , ë¶ˆí™•ì‹¤í•œ ê°€ì •ì€ ëª…ì‹œí•˜ì„¸ìš”.
"""

# =========================
# BX ìƒì„±
# =========================
if submitted:
    if not company or not request:
        st.warning("ê¸°ì—…ëª…ê³¼ ìš”ì²­ì‚¬í•­(ë¸Œë¦¬í”„)ì€ í•„ìˆ˜ì…ë‹ˆë‹¤.")
    elif not client:
        st.warning("ğŸ”‘ OpenAI API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        with st.spinner("BX ìë£Œ ìƒì„± ì¤‘â€¦"):
            prompt = build_user_prompt(
                company, industry, region, competitors, target, mode, request,
                constraints, tone, depth,
                corpus_summ=corpus_summ,
                sources=corpus if corpus else []
            )
            resp = client.chat.completions.create(
                model=model,
                messages=[{"role": "system", "content": build_system_prompt()},
                          {"role": "user", "content": prompt}],
                temperature=temperature,
                max_tokens=max_tokens,
            )
        content = resp.choices[0].message.content
        st.success("ì™„ë£Œ! ì•„ë˜ ê²°ê³¼ë¥¼ ê²€í† í•˜ì„¸ìš”.")
        st.markdown(content)

        # ë‹¤ìš´ë¡œë“œ
        cA, cB = st.columns(2)
        with cA:
            st.download_button(
                "ğŸ’¾ TXTë¡œ ì €ì¥",
                data=content,
                file_name=f"{company}_BX_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
                mime="text/plain",
                use_container_width=True,
            )
        with cB:
            st.download_button(
                "ğŸ’¾ JSONë¡œ ì €ì¥",
                data=json.dumps({
                    "company": company, "industry": industry, "region": region,
                    "competitors": competitors, "target": target, "mode": mode,
                    "tone": tone, "depth": depth, "constraints": constraints,
                    "sources": [{"title": x.get("title"), "url": x.get("url")} for x in (corpus or [])],
                    "corpus_summary": corpus_summ,
                    "content": content
                }, ensure_ascii=False, indent=2),
                file_name=f"{company}_BX_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                mime="application/json",
                use_container_width=True,
            )

# =========================
# ê³ ì • íë ˆì´ì…˜(ë ˆí¼ëŸ°ìŠ¤ ì‚¬ì´íŠ¸)
# =========================
st.markdown("### ğŸ”— ì°¸ê³ í•  ë§Œí•œ ì‚¬ë¡€/ê°€ì´ë“œ (íë ˆì´ì…˜)")
colr1, colr2, colr3 = st.columns(3)
with colr1:
    st.markdown("- **Behance | Branding Case Studies** â€“ ë‹¤ì–‘í•œ ë¸Œëœë“œ ì¼€ì´ìŠ¤")
    st.markdown("  - https://www.behance.net/search/projects/branding%20case%20study")
    st.markdown("- **Awwwards** â€“ íŠ¸ë Œë””í•œ ì›¹/ë¸Œëœë”© ì‚¬ì´íŠ¸")
    st.markdown("  - https://www.awwwards.com/websites/")
with colr2:
    st.markdown("- **Brand New (UnderConsideration)** â€“ ë¦¬ë¸Œëœë”© ì‚¬ë¡€ ë¦¬ë·°")
    st.markdown("  - https://www.underconsideration.com/brandnew/archives/complete")
    st.markdown("- **BP&O** â€“ ë¸Œëœë”©/íŒ¨í‚¤ì§• ë¦¬ë·° & ì¸ì‚¬ì´íŠ¸")
    st.markdown("  - https://bpando.org/")
with colr3:
    st.markdown("- **Atlassian Design System** â€“ ë¡œê³ /í† í°/ì½˜í…ì¸  ê°€ì´ë“œ")
    st.markdown("  - https://atlassian.design/")
    st.markdown("- **IBM Design Language**")
    st.markdown("  - https://www.ibm.com/design/language/")
    st.markdown("- **Material Design 3**")
    st.markdown("  - https://m3.material.io/")
    st.markdown("- **Apple HIG â€“ Branding**")
    st.markdown("  - https://developer.apple.com/design/human-interface-guidelines/branding")
